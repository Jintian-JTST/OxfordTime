"""
WeChat Annual Chat Analysis
==========================
- Yearly analysis for a single year
- GitHub-style activity heatmap
- Per-talker profiles (JSON)
- HTML report with explicit Top Talkers section
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import jieba
from wordcloud import WordCloud
from io import BytesIO
import base64
import json

# ===================== é…ç½® =====================
TARGET_YEAR = 2025
CSV_PATH = "messages.csv"
TOP_N_TALKERS = 5

FONT_PATH = "C:/Windows/Fonts/msyh.ttc"
# FONT_PATH = "/System/Library/Fonts/PingFang.ttc"

# ===================== å·¥å…·å‡½æ•° =====================
def set_font():
    plt.rcParams["font.sans-serif"] = [
        "Microsoft YaHei", "SimHei", "Arial Unicode MS"
    ]
    plt.rcParams["axes.unicode_minus"] = False


def fig_to_base64(fig):
    buf = BytesIO()
    fig.savefig(buf, format="png", dpi=120, bbox_inches="tight")
    buf.seek(0)
    img = base64.b64encode(buf.read()).decode()
    plt.close(fig)
    return img


# ===================== æ•°æ®åŠ è½½ =====================
def load_data():
    try:
        df = pd.read_csv(CSV_PATH, encoding="utf-8", on_bad_lines="skip")
    except UnicodeDecodeError:
        df = pd.read_csv(CSV_PATH, encoding="gbk", on_bad_lines="skip")

    df = df[df["Type"] == 1].copy()
    df["dt"] = pd.to_datetime(df["StrTime"], errors="coerce")
    df = df.dropna(subset=["dt"])
    df = df[df["dt"].dt.year == TARGET_YEAR]

    df["Date"] = df["dt"].dt.date
    df["Month"] = df["dt"].dt.month
    df["Hour"] = df["dt"].dt.hour
    df["Weekday"] = df["dt"].dt.weekday
    df["StrContent"] = df["StrContent"].fillna("")

    return df


# ===================== æ€»ä½“ç»Ÿè®¡ =====================
def summary_metrics(df):
    total = len(df)
    sent = (df["IsSender"] == 1).sum()
    received = (df["IsSender"] == 0).sum()
    active_days = df["Date"].nunique()

    return {
        "total": total,
        "sent": sent,
        "received": received,
        "avg_active": round(total / active_days, 1),
        "start": df["dt"].min().strftime("%Y-%m-%d"),
        "end": df["dt"].max().strftime("%Y-%m-%d"),
    }


# ===================== å›¾è¡¨æ¨¡å— =====================
def monthly_trend(df):
    set_font()
    data = df.groupby("Month").size().reindex(range(1, 13), fill_value=0)

    fig, ax = plt.subplots(figsize=(10, 4))
    ax.plot(data.index, data.values, marker="o")
    ax.set_title("æœˆåº¦èŠå¤©è¶‹åŠ¿")
    ax.set_xlabel("æœˆä»½")
    ax.set_ylabel("æ¶ˆæ¯æ•°")
    ax.set_xticks(range(1, 13))
    ax.grid(alpha=0.3)

    return fig_to_base64(fig)


def yearly_heatmap(df):
    set_font()
    daily = df.groupby("Date").size()

    year_start = pd.Timestamp(f"{TARGET_YEAR}-01-01")
    all_days = pd.date_range(year_start, f"{TARGET_YEAR}-12-31", freq="D")

    full = pd.DataFrame({"Date": all_days})
    full["count"] = full["Date"].dt.date.map(daily).fillna(0).astype(int)
    full["day_index"] = (full["Date"] - year_start).dt.days
    full["week_index"] = full["day_index"] // 7
    full["weekday"] = full["Date"].dt.weekday

    heatmap = full.pivot(
        index="weekday", columns="week_index", values="count"
    )

    fig, ax = plt.subplots(figsize=(16, 3))
    sns.heatmap(
        heatmap,
        cmap="Greens",
        linewidths=0.3,
        linecolor="white",
        ax=ax
    )

    ax.set_yticks(range(7))
    ax.set_yticklabels(
        ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"], rotation=0
    )
    ax.set_title("å¹´åº¦èŠå¤©æ´»è·ƒåº¦çƒ­åŠ›å›¾ï¼ˆGitHub é£æ ¼ï¼‰")
    ax.set_xlabel("Week of Year")
    ax.set_ylabel("")

    return fig_to_base64(fig)


def wordcloud_plot(df):
    text = " ".join(df["StrContent"])
    stopwords = {
        "çš„","äº†","æˆ‘","æ˜¯","åœ¨","ä¹Ÿ","æœ‰","å°±","ä¸","äºº",
        "æˆ‘ä»¬","å“ˆå“ˆ","å“ˆå“ˆå“ˆ","å›¾ç‰‡","è§†é¢‘"
    }
    words = [w for w in jieba.cut(text) if len(w) > 1 and w not in stopwords]
    if not words:
        return ""

    wc = WordCloud(
        font_path=FONT_PATH,
        width=900,
        height=400,
        background_color="white"
    ).generate(" ".join(words))

    fig, ax = plt.subplots(figsize=(10, 4))
    ax.imshow(wc)
    ax.axis("off")
    return fig_to_base64(fig)


# ===================== èŠå¤©å¯¹è±¡ç”»åƒ =====================
def analyze_single_talker(df, talker_id):
    sub = df[df["TalkerId"] == talker_id]
    if sub.empty:
        return None

    name = sub["NickName"].value_counts().idxmax()
    daily_counts = sub.groupby("Date").size()

    return {
        "talker_id": int(talker_id),
        "name": name,
        "total_msgs": int(len(sub)),
        "active_days": int(sub["Date"].nunique()),
        "first_date": str(sub["dt"].min().date()),
        "last_date": str(sub["dt"].max().date()),
        "max_daily_msgs": int(daily_counts.max()),
    }


def analyze_all_talkers(df):
    counts = df["TalkerId"].value_counts()
    profiles = []

    for tid in counts.index:
        p = analyze_single_talker(df, tid)
        if p:
            profiles.append(p)

    return profiles


# ===================== HTML æŠ¥å‘Š =====================
def render_top_talkers_html(top_talkers):
    blocks = []
    for i, t in enumerate(top_talkers, start=1):
        blocks.append(f"""
        <div class="card">
        <h3>#{i} {t['name']}</h3>
        <ul>
          <li>å¹´åº¦æ¶ˆæ¯æ•°ï¼š{t['total_msgs']}</li>
          <li>æ´»è·ƒå¤©æ•°ï¼š{t['active_days']}</li>
          <li>æ—¶é—´è·¨åº¦ï¼š{t['first_date']} â†’ {t['last_date']}</li>
          <li>å•æ—¥æœ€é«˜æ¶ˆæ¯æ•°ï¼š{t['max_daily_msgs']}</li>
        </ul>
        </div>
        """)
    return "\n".join(blocks)


def generate_html(metrics, charts, top_talkers):
    top_html = render_top_talkers_html(top_talkers)

    html = f"""
<html>
<head>
<meta charset="utf-8">
<title>{TARGET_YEAR} å¾®ä¿¡å¹´åº¦æŠ¥å‘Š</title>
<style>
body {{
  font-family: 'Microsoft YaHei', Arial;
  max-width: 900px;
  margin: auto;
  padding: 40px;
  background: #f7f9fc;
}}
.card {{
  background: white;
  padding: 30px;
  margin-bottom: 30px;
  border-radius: 12px;
  box-shadow: 0 4px 15px rgba(0,0,0,0.05);
}}
h1 {{ text-align: center; }}
h2 {{ border-left: 5px solid #2ecc71; padding-left: 12px; }}
h3 {{ margin-top: 0; }}
img {{ max-width: 100%; }}
</style>
</head>

<body>

<h1>{TARGET_YEAR} å¹´åº¦å¾®ä¿¡å›å¿†å½•</h1>

<div class="card">
<h2>ğŸ“Š æ ¸å¿ƒç»Ÿè®¡</h2>
<ul>
<li>æ€»æ¶ˆæ¯æ•°ï¼š{metrics["total"]}</li>
<li>æˆ‘å‘é€ï¼š{metrics["sent"]} ï½œ æ”¶åˆ°ï¼š{metrics["received"]}</li>
<li>æ´»è·ƒæ—¥å‡æ¶ˆæ¯ï¼š{metrics["avg_active"]}</li>
</ul>
</div>

<div class="card"><h2>ğŸ† å¹´åº¦æœ€å¸¸è”ç³»çš„èŠå¤©å¯¹è±¡</h2>
{top_html}
</div>

<div class="card"><h2>ğŸ“… æœˆåº¦è¶‹åŠ¿</h2>
<img src="data:image/png;base64,{charts['monthly']}"></div>

<div class="card"><h2>ğŸŸ© å¹´åº¦çƒ­åŠ›å›¾</h2>
<img src="data:image/png;base64,{charts['heatmap']}"></div>

<div class="card"><h2>ğŸ’­ å¹´åº¦å…³é”®è¯</h2>
<img src="data:image/png;base64,{charts['wordcloud']}"></div>

<p style="text-align:center;color:#aaa;font-size:12px;">
Generated by Python Â· Chat Analysis
</p>

</body>
</html>
"""

    filename = f"WeChat_Report_{TARGET_YEAR}.html"
    with open(filename, "w", encoding="utf-8") as f:
        f.write(html)

    print(f"âœ… HTML æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼š{filename}")


# ===================== ä¸»ç¨‹åº =====================
if __name__ == "__main__":
    df = load_data()
    if df.empty:
        print("âš ï¸ è¯¥å¹´ä»½æ— æ•°æ®")
        exit()

    metrics = summary_metrics(df)
    all_profiles = analyze_all_talkers(df)

    # æ’åºï¼Œé€‰ Top N
    top_talkers = sorted(
        all_profiles,
        key=lambda x: x["total_msgs"],
        reverse=True
    )[:TOP_N_TALKERS]

    charts = {
        "monthly": monthly_trend(df),
        "heatmap": yearly_heatmap(df),
        "wordcloud": wordcloud_plot(df),
    }

    generate_html(metrics, charts, top_talkers)

    with open(
        f"talker_profiles_{TARGET_YEAR}.json",
        "w",
        encoding="utf-8"
    ) as f:
        json.dump(all_profiles, f, ensure_ascii=False, indent=2)

    print(f"âœ… å·²ç”Ÿæˆ talker_profiles_{TARGET_YEAR}.json")
